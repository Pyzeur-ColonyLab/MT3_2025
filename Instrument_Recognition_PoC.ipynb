{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéµ Instrument Recognition PoC\n",
    "\n",
    "**Goal**: Identify specific instruments present in audio using MIDI transcription + timbre matching\n",
    "\n",
    "**Pipeline**:\n",
    "- **Phase 0** (This notebook): MIDI transcription with YourMT3 ‚úÖ\n",
    "- **Phase 1**: YAMNet setup and instrument mapping (521 ‚Üí 25 categories) üöß\n",
    "- **Phase 2**: Note isolation from MIDI piano roll üöß\n",
    "- **Phase 3**: Timbre matching with YAMNet üöß\n",
    "- **Phase 4**: Output generation (aggregated % + timeline) üöß\n",
    "- **Phase 5**: Accuracy evaluation üöß\n",
    "\n",
    "**Reference**: See `instrument_recognition/SPECIFICATION.md` for full technical details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è IMPORTANT: Run cells in order (1‚Üí2‚Üí3‚Üí4‚Üí5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Change to yourmt3_space directory\n",
    "original_dir = os.getcwd()\n",
    "if not os.path.exists('yourmt3_space'):\n",
    "    print(\"‚ùå Error: yourmt3_space directory not found!\")\n",
    "    print(\"   Run setup_yourmt3_brev.sh first\")\n",
    "else:\n",
    "    os.chdir('yourmt3_space')\n",
    "    sys.path.insert(0, '.')\n",
    "    sys.path.insert(0, 'amt/src')\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "from IPython.display import Audio, display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "from model_helper import load_model_checkpoint, transcribe\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(f\"   Working directory: {os.getcwd()}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load YourMT3 Model\n",
    "\n",
    "**Model**: YPTF.MoE+Multi (noPS) - 536M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading YourMT3 model...\")\n",
    "print(\"This may take 10-15 seconds...\")\n",
    "\n",
    "# Model configuration\n",
    "checkpoint = \"mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops@last.ckpt\"\n",
    "project = '2024'\n",
    "precision = '16'\n",
    "\n",
    "args = [\n",
    "    checkpoint,\n",
    "    '-p', project,\n",
    "    '-tk', 'mc13_full_plus_256',\n",
    "    '-dec', 'multi-t5',\n",
    "    '-nl', '26',\n",
    "    '-enc', 'perceiver-tf',\n",
    "    '-sqr', '1',\n",
    "    '-ff', 'moe',\n",
    "    '-wf', '4',\n",
    "    '-nmoe', '8',\n",
    "    '-kmoe', '2',\n",
    "    '-act', 'silu',\n",
    "    '-epe', 'rope',\n",
    "    '-rp', '1',\n",
    "    '-ac', 'spec',\n",
    "    '-hop', '300',\n",
    "    '-atc', '1',\n",
    "    '-pr', precision\n",
    "]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = load_model_checkpoint(args=args, device=device)\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Model: YPTF.MoE+Multi (noPS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Functions - Phase 0 (MIDI Transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_midi(midi_path):\n",
    "    \"\"\"Analyze MIDI file and return statistics\"\"\"\n",
    "    midi = pretty_midi.PrettyMIDI(midi_path)\n",
    "    \n",
    "    stats = {\n",
    "        'total_notes': sum(len(inst.notes) for inst in midi.instruments),\n",
    "        'num_instruments': len(midi.instruments),\n",
    "        'duration': midi.get_end_time(),\n",
    "        'instruments': []\n",
    "    }\n",
    "    \n",
    "    for i, inst in enumerate(midi.instruments):\n",
    "        if len(inst.notes) > 0:\n",
    "            stats['instruments'].append({\n",
    "                'index': i,\n",
    "                'program': inst.program,\n",
    "                'name': pretty_midi.program_to_instrument_name(inst.program),\n",
    "                'notes': len(inst.notes),\n",
    "                'is_drum': inst.is_drum\n",
    "            })\n",
    "    \n",
    "    return stats, midi\n",
    "\n",
    "def transcribe_audio(audio_path, output_name):\n",
    "    \"\"\"Transcribe audio and return MIDI path + stats\"\"\"\n",
    "    info = torchaudio.info(audio_path)\n",
    "    duration = info.num_frames / info.sample_rate\n",
    "    \n",
    "    audio_info = {\n",
    "        \"filepath\": audio_path,\n",
    "        \"track_name\": output_name,\n",
    "        \"sample_rate\": int(info.sample_rate),\n",
    "        \"bits_per_sample\": int(info.bits_per_sample) if info.bits_per_sample else 16,\n",
    "        \"num_channels\": int(info.num_channels),\n",
    "        \"num_frames\": int(info.num_frames),\n",
    "        \"duration\": int(duration),\n",
    "        \"encoding\": 'unknown',\n",
    "    }\n",
    "    \n",
    "    # Transcribe\n",
    "    midi_path = transcribe(model, audio_info)\n",
    "    \n",
    "    # Analyze\n",
    "    stats, midi = analyze_midi(midi_path)\n",
    "    \n",
    "    return midi_path, stats, midi\n",
    "\n",
    "def midi_to_audio(midi_path, sample_rate=16000):\n",
    "    \"\"\"Convert MIDI to audio for playback using FluidSynth\"\"\"\n",
    "    try:\n",
    "        midi = pretty_midi.PrettyMIDI(midi_path)\n",
    "        audio = midi.fluidsynth(fs=sample_rate)\n",
    "        return audio, sample_rate\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  MIDI synthesis failed: {e}\")\n",
    "        print(\"   Note: FluidSynth may not be installed\")\n",
    "        return None, None\n",
    "\n",
    "def plot_piano_roll(midi, title, ax=None):\n",
    "    \"\"\"Plot piano roll from MIDI object\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(16, 6))\n",
    "    \n",
    "    # Get all notes\n",
    "    notes_to_plot = []\n",
    "    colors = plt.cm.tab20.colors\n",
    "    \n",
    "    for inst_idx, inst in enumerate(midi.instruments):\n",
    "        color = colors[inst_idx % len(colors)]\n",
    "        for note in inst.notes:\n",
    "            notes_to_plot.append({\n",
    "                'start': note.start,\n",
    "                'end': note.end,\n",
    "                'pitch': note.pitch,\n",
    "                'velocity': note.velocity,\n",
    "                'color': color,\n",
    "                'instrument': inst.program,\n",
    "                'is_drum': inst.is_drum\n",
    "            })\n",
    "    \n",
    "    # Plot notes\n",
    "    for note_info in notes_to_plot:\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle(\n",
    "                (note_info['start'], note_info['pitch']),\n",
    "                note_info['end'] - note_info['start'],\n",
    "                1,\n",
    "                facecolor=note_info['color'],\n",
    "                edgecolor='black',\n",
    "                linewidth=0.5,\n",
    "                alpha=0.7\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    ax.set_xlim(0, midi.get_end_time())\n",
    "    ax.set_ylim(20, 108)  # Piano range\n",
    "    ax.set_xlabel('Time (seconds)', fontsize=12)\n",
    "    ax.set_ylabel('MIDI Pitch', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add note count\n",
    "    total_notes = len(notes_to_plot)\n",
    "    ax.text(0.98, 0.02, f'{total_notes} notes', \n",
    "            transform=ax.transAxes,\n",
    "            ha='right', va='bottom',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "            fontsize=10)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "print(\"‚úÖ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find audio files\n",
    "audio_extensions = ['*.mp3', '*.wav', '*.flac', '*.m4a', '*.ogg']\n",
    "audio_files = []\n",
    "for ext in audio_extensions:\n",
    "    audio_files.extend(glob.glob(os.path.join(original_dir, ext)))\n",
    "\n",
    "if len(audio_files) == 0:\n",
    "    print(\"‚ùå No audio files found!\")\n",
    "    print(\"   Please upload audio files to the MT3 directory\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found {len(audio_files)} audio files:\")\n",
    "    for i, f in enumerate(audio_files):\n",
    "        info = torchaudio.info(f)\n",
    "        duration = info.num_frames / info.sample_rate\n",
    "        print(f\"   {i+1}. {os.path.basename(f)} ({duration:.1f}s)\")\n",
    "\n",
    "# File selector\n",
    "file_selector = widgets.Dropdown(\n",
    "    options=[(f\"{os.path.basename(f)} ({torchaudio.info(f).num_frames/torchaudio.info(f).sample_rate:.1f}s)\", f) for f in audio_files],\n",
    "    description='Test File:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='700px')\n",
    ")\n",
    "\n",
    "display(file_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Phase 0: MIDI Transcription\n",
    "\n",
    "**Goal**: Generate MIDI transcription from audio using YourMT3\n",
    "\n",
    "**Output**: MIDI file with multi-instrument transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global results storage\n",
    "phase0_results = {}\n",
    "\n",
    "def run_phase0(button):\n",
    "    global phase0_results\n",
    "    \n",
    "    output.clear_output(wait=True)\n",
    "    \n",
    "    with output:\n",
    "        audio_path = file_selector.value\n",
    "        \n",
    "        if not audio_path:\n",
    "            print(\"‚ùå Please select an audio file first!\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(\"üéØ PHASE 0: MIDI Transcription\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\nüìÅ Input File: {os.path.basename(audio_path)}\")\n",
    "        \n",
    "        try:\n",
    "            # Transcribe\n",
    "            print(\"\\nüéµ Running YourMT3 transcription...\")\n",
    "            print(\"   This may take 30-60 seconds...\")\n",
    "            \n",
    "            midi_path, stats, midi = transcribe_audio(audio_path, \"instrument_recognition\")\n",
    "            \n",
    "            # Store results\n",
    "            phase0_results = {\n",
    "                'audio_path': audio_path,\n",
    "                'midi_path': midi_path,\n",
    "                'stats': stats,\n",
    "                'midi': midi\n",
    "            }\n",
    "            \n",
    "            # Display results\n",
    "            print(f\"\\n‚úÖ Transcription Complete:\")\n",
    "            print(f\"   MIDI file: {midi_path}\")\n",
    "            print(f\"   Total notes: {stats['total_notes']}\")\n",
    "            print(f\"   Instruments detected: {stats['num_instruments']}\")\n",
    "            print(f\"   Duration: {stats['duration']:.2f}s\")\n",
    "            \n",
    "            # Show instrument breakdown\n",
    "            print(f\"\\nüé∏ Detected Instruments:\")\n",
    "            for inst in stats['instruments']:\n",
    "                drum_label = \"(Drums)\" if inst['is_drum'] else \"\"\n",
    "                print(f\"   - {inst['name']} {drum_label}: {inst['notes']} notes (Program {inst['program']})\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"‚úÖ PHASE 0 COMPLETE!\")\n",
    "            print(\"=\"*80)\n",
    "            print(\"\\nRun the cells below to:\")\n",
    "            print(\"   - View piano roll visualization\")\n",
    "            print(\"   - Listen to MIDI playback\")\n",
    "            print(\"   - Proceed to Phase 1 (YAMNet setup)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Transcription failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Create button and output\n",
    "phase0_button = widgets.Button(\n",
    "    description='üöÄ Run Phase 0',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='50px')\n",
    ")\n",
    "phase0_button.on_click(run_phase0)\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "print(\"‚ö†Ô∏è  Note: Transcription takes ~30-60 seconds depending on audio length\")\n",
    "print(\"\\n‚úÖ Ready! Click the button below to start Phase 0\")\n",
    "\n",
    "display(phase0_button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View MIDI Results\n",
    "\n",
    "*Run this after Phase 0 completes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if phase0_results:\n",
    "    print(\"üéπ MIDI Transcription Results\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    stats = phase0_results['stats']\n",
    "    midi = phase0_results['midi']\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    print(f\"   Audio: {os.path.basename(phase0_results['audio_path'])}\")\n",
    "    print(f\"   MIDI: {phase0_results['midi_path']}\")\n",
    "    print(f\"   Total notes: {stats['total_notes']}\")\n",
    "    print(f\"   Instruments: {stats['num_instruments']}\")\n",
    "    print(f\"   Duration: {stats['duration']:.2f}s\")\n",
    "    \n",
    "    # Piano roll visualization\n",
    "    print(f\"\\nüéπ Piano Roll:\")\n",
    "    fig, ax = plt.subplots(figsize=(18, 6))\n",
    "    plot_piano_roll(midi, 'üéµ MIDI Transcription - Phase 0', ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # MIDI playback\n",
    "    print(f\"\\nüîä MIDI Playback:\")\n",
    "    audio, sr = midi_to_audio(phase0_results['midi_path'])\n",
    "    if audio is not None:\n",
    "        display(Audio(audio, rate=sr))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ Phase 0 complete!\")\n",
    "    print(\"\\nüí° Next Steps:\")\n",
    "    print(\"   ‚Üí Phase 1: Set up YAMNet for timbre matching\")\n",
    "    print(\"   ‚Üí Phase 2: Extract isolated notes from MIDI piano roll\")\n",
    "    print(\"   ‚Üí Phase 3: Match notes to instrument timbres\")\n",
    "    print(\"   ‚Üí Phase 4: Generate aggregated % and timeline outputs\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Run Phase 0 first (Cell 5)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöß Phase 1: YAMNet Setup (Coming Next)\n",
    "\n",
    "**Goal**: Load YAMNet model and create instrument mapping\n",
    "\n",
    "**Tasks**:\n",
    "1. Install TensorFlow and YAMNet dependencies\n",
    "2. Load pretrained YAMNet model\n",
    "3. Create mapping: 521 AudioSet classes ‚Üí 25 Level 2 instrument categories\n",
    "4. Test YAMNet on sample audio segments\n",
    "\n",
    "**Status**: Not implemented yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöß Phase 2: Note Isolation (Coming Next)\n",
    "\n",
    "**Goal**: Extract isolated notes from MIDI for timbre matching\n",
    "\n",
    "**Tasks**:\n",
    "1. Parse MIDI piano roll to identify individual notes\n",
    "2. Extract corresponding audio segments from original audio\n",
    "3. Score isolation quality (temporal, pitch, energy)\n",
    "4. Select top N isolated notes per MIDI instrument\n",
    "\n",
    "**Status**: Not implemented yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöß Phase 3: Timbre Matching (Coming Next)\n",
    "\n",
    "**Goal**: Match isolated notes to real instrument timbres using YAMNet\n",
    "\n",
    "**Tasks**:\n",
    "1. Run YAMNet inference on isolated audio segments\n",
    "2. Aggregate predictions per MIDI instrument\n",
    "3. Vote on most likely real instrument match\n",
    "4. Generate confidence scores\n",
    "\n",
    "**Status**: Not implemented yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöß Phase 4: Output Generation (Coming Next)\n",
    "\n",
    "**Goal**: Create final outputs - aggregated % and timeline\n",
    "\n",
    "**Tasks**:\n",
    "1. **Output B**: Aggregated instrument percentages (e.g., \"Electric Guitar: 35%, Piano: 25%, ...\")\n",
    "2. **Output C**: Timeline of instrument presence (e.g., \"0-30s: Piano, 30-60s: Guitar + Drums\")\n",
    "3. Visualization: Piano roll with identified instruments\n",
    "4. Save results to JSON/CSV\n",
    "\n",
    "**Status**: Not implemented yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöß Phase 5: Evaluation (Coming Next)\n",
    "\n",
    "**Goal**: Assess accuracy and tune thresholds\n",
    "\n",
    "**Tasks**:\n",
    "1. Manual evaluation against ground truth\n",
    "2. Calculate accuracy metrics\n",
    "3. Error analysis (common misclassifications)\n",
    "4. Threshold tuning for optimal performance\n",
    "\n",
    "**Target**: 85% accuracy, 80% instrument coverage\n",
    "\n",
    "**Status**: Not implemented yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìã Implementation Checklist\n",
    "\n",
    "**Phase 0** (Current):\n",
    "- ‚úÖ YourMT3 model loading\n",
    "- ‚úÖ Audio file selection\n",
    "- ‚úÖ MIDI transcription\n",
    "- ‚úÖ MIDI analysis and visualization\n",
    "\n",
    "**Phase 1** (Next):\n",
    "- ‚¨ú Install TensorFlow + YAMNet\n",
    "- ‚¨ú Load pretrained YAMNet model\n",
    "- ‚¨ú Create 521‚Üí25 instrument mapping\n",
    "- ‚¨ú Test YAMNet inference\n",
    "\n",
    "**Phase 2-5**:\n",
    "- ‚¨ú Note isolation algorithm\n",
    "- ‚¨ú Isolation quality scoring\n",
    "- ‚¨ú YAMNet timbre matching\n",
    "- ‚¨ú Aggregated output generation\n",
    "- ‚¨ú Timeline output generation\n",
    "- ‚¨ú Visualization\n",
    "- ‚¨ú Accuracy evaluation\n",
    "\n",
    "**Reference**: See `instrument_recognition/SPECIFICATION.md` for detailed technical specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Assisted by Claude Code*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
