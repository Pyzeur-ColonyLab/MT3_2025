{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfb5 Stems Separation PoC: Accuracy Comparison\n",
    "\n",
    "**Proof of Concept** to validate Idea 1: Stems-based transcription approach.\n",
    "\n",
    "**Hypothesis**: Separating audio into stems (bass, drums, other, vocals) before transcription improves accuracy.\n",
    "\n",
    "**Test**:\n",
    "1. Transcribe **full mix** with YourMT3\n",
    "2. Separate audio into **4 stems** with Demucs\n",
    "3. Transcribe **each stem** with YourMT3\n",
    "4. Compare accuracy and analyze improvements\n",
    "\n",
    "**Expected**: 10-15% accuracy improvement on stems (without fine-tuning yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u26a0\ufe0f IMPORTANT: Run cells in order (1\u21922\u21923\u21924\u21925)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Change to yourmt3_space directory\n",
    "original_dir = os.getcwd()\n",
    "if not os.path.exists('yourmt3_space'):\n",
    "    print(\"\u274c Error: yourmt3_space directory not found!\")\n",
    "    print(\"   Run setup_yourmt3_brev.sh first\")\n",
    "else:\n",
    "    os.chdir('yourmt3_space')\n",
    "    sys.path.insert(0, '.')\n",
    "    sys.path.insert(0, 'amt/src')\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "from IPython.display import Audio, display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "from model_helper import load_model_checkpoint, transcribe\n",
    "\n",
    "print(\"\u2705 Imports successful!\")\n",
    "print(f\"   Working directory: {os.getcwd()}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Demucs (as Python library)\n",
    "\n",
    "**Run this cell once** - it will import and prepare Demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Demucs as a Python library (no subprocess needed!)\n",
    "try:\n",
    "    from demucs.pretrained import get_model\n",
    "    from demucs.apply import apply_model\n",
    "    print(\"\u2705 Demucs imported successfully!\")\n",
    "    \n",
    "    # Pre-load the htdemucs model\n",
    "    print(\"\ud83d\udce6 Loading htdemucs model...\")\n",
    "    print(\"   (This will download ~80MB on first run)\")\n",
    "    demucs_model = get_model('htdemucs')\n",
    "    demucs_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    demucs_model.to(demucs_device)\n",
    "    print(f\"\u2705 Demucs model loaded on {demucs_device}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(\"\u274c Demucs not installed!\")\n",
    "    print(\"   Installing demucs...\")\n",
    "    import subprocess\n",
    "    subprocess.run(['pip', 'install', '-q', 'demucs'], check=True)\n",
    "    print(\"\u2705 Demucs installed! Please restart kernel and re-run this cell.\")\n",
    "    demucs_model = None\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error loading Demucs: {e}\")\n",
    "    demucs_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load YourMT3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading YourMT3 model...\")\n",
    "print(\"This may take 10-15 seconds...\")\n",
    "\n",
    "# Model configuration\n",
    "checkpoint = \"mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops@last.ckpt\"\n",
    "project = '2024'\n",
    "precision = '16'\n",
    "\n",
    "args = [\n",
    "    checkpoint,\n",
    "    '-p', project,\n",
    "    '-tk', 'mc13_full_plus_256',\n",
    "    '-dec', 'multi-t5',\n",
    "    '-nl', '26',\n",
    "    '-enc', 'perceiver-tf',\n",
    "    '-sqr', '1',\n",
    "    '-ff', 'moe',\n",
    "    '-wf', '4',\n",
    "    '-nmoe', '8',\n",
    "    '-kmoe', '2',\n",
    "    '-act', 'silu',\n",
    "    '-epe', 'rope',\n",
    "    '-rp', '1',\n",
    "    '-ac', 'spec',\n",
    "    '-hop', '300',\n",
    "    '-atc', '1',\n",
    "    '-pr', precision\n",
    "]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = load_model_checkpoint(args=args, device=device)\n",
    "\n",
    "print(\"\\n\u2705 Model loaded successfully!\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Model: YPTF.MoE+Multi (noPS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Helper Functions for PoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_stems_demucs(audio_path, output_dir=\"separated\"):",
    "    \"\"\"Separate audio into 4 stems using Demucs Python API\"\"\"",
    "    print(f\"\ud83c\udfb5 Separating stems with Demucs...\")",
    "    print(f\"   Input: {audio_path}\")",
    "    print(f\"   Output: {output_dir}/\")",
    "    print(\"   This may take 30-60 seconds...\")",
    "    ",
    "    if demucs_model is None:",
    "        print(\"\\n\u274c Demucs model not loaded!\")",
    "        print(\"   Please run Cell 2 first\")",
    "        return None",
    "    ",
    "    try:",
    "        # Load audio",
    "        wav, sr = torchaudio.load(audio_path)",
    "        ",
    "        # Demucs expects 44.1kHz, resample if needed",
    "        if sr != 44100:",
    "            resampler = torchaudio.transforms.Resample(sr, 44100)",
    "            wav = resampler(wav)",
    "            sr = 44100",
    "        ",
    "        # Convert to mono if stereo (Demucs expects mono or stereo)",
    "        if wav.shape[0] > 2:",
    "            wav = wav[:2]  # Take first 2 channels",
    "        ",
    "        # Apply Demucs model",
    "        print(\"   Running separation...\")",
    "        wav = wav.to(demucs_device)",
    "        ",
    "        with torch.no_grad():",
    "            sources = apply_model(demucs_model, wav[None], device=demucs_device)[0]",
    "        ",
    "        # sources shape: [4, channels, samples]",
    "        # Order: drums, bass, other, vocals",
    "        stems_order = ['drums', 'bass', 'other', 'vocals']",
    "        ",
    "        # Create output directory",
    "        track_name = Path(audio_path).stem",
    "        stem_dir = Path(output_dir) / 'htdemucs' / track_name",
    "        stem_dir.mkdir(parents=True, exist_ok=True)",
    "        ",
    "        stems = {}",
    "        ",
    "        # Save each stem",
    "        for i, stem_name in enumerate(stems_order):",
    "            stem_path = stem_dir / f\"{stem_name}.wav\"",
    "            stem_audio = sources[i].cpu()",
    "            torchaudio.save(str(stem_path), stem_audio, sr)",
    "            stems[stem_name] = str(stem_path)",
    "        ",
    "        print(\"\u2705 Stems separated successfully!\")",
    "        for stem_name in stems_order:",
    "            print(f\"   - {stem_name}.wav\")",
    "        ",
    "        return stems",
    "        ",
    "    except Exception as e:",
    "        print(f\"\u274c Demucs separation failed: {e}\")",
    "        import traceback",
    "        traceback.print_exc()",
    "        return None",
    "",
    "def analyze_midi(midi_path):",
    "    \"\"\"Analyze MIDI file and return statistics\"\"\"",
    "    midi = pretty_midi.PrettyMIDI(midi_path)",
    "    ",
    "    stats = {",
    "        'total_notes': sum(len(inst.notes) for inst in midi.instruments),",
    "        'num_instruments': len(midi.instruments),",
    "        'duration': midi.get_end_time(),",
    "        'instruments': []",
    "    }",
    "    ",
    "    for i, inst in enumerate(midi.instruments):",
    "        if len(inst.notes) > 0:",
    "            stats['instruments'].append({",
    "                'index': i,",
    "                'program': inst.program,",
    "                'name': pretty_midi.program_to_instrument_name(inst.program),",
    "                'notes': len(inst.notes),",
    "                'is_drum': inst.is_drum",
    "            })",
    "    ",
    "    return stats, midi",
    "",
    "def transcribe_audio(audio_path, output_name):",
    "    \"\"\"Transcribe audio and return MIDI path + stats\"\"\"",
    "    info = torchaudio.info(audio_path)",
    "    duration = info.num_frames / info.sample_rate",
    "    ",
    "    audio_info = {",
    "        \"filepath\": audio_path,",
    "        \"track_name\": output_name,",
    "        \"sample_rate\": int(info.sample_rate),",
    "        \"bits_per_sample\": int(info.bits_per_sample) if info.bits_per_sample else 16,",
    "        \"num_channels\": int(info.num_channels),",
    "        \"num_frames\": int(info.num_frames),",
    "        \"duration\": int(duration),",
    "        \"encoding\": 'unknown',",
    "    }",
    "    ",
    "    # Transcribe",
    "    midi_path = transcribe(model, audio_info)",
    "    ",
    "    # Analyze",
    "    stats, midi = analyze_midi(midi_path)",
    "    ",
    "    return midi_path, stats",
    "",
    "",
    "def midi_to_audio(midi_path, sample_rate=16000):",
    "    \"\"\"Convert MIDI to audio for playback using FluidSynth\"\"\"",
    "    try:",
    "        midi = pretty_midi.PrettyMIDI(midi_path)",
    "        audio = midi.fluidsynth(fs=sample_rate)",
    "        return audio, sample_rate",
    "    except Exception as e:",
    "        print(f\"\u26a0\ufe0f  MIDI synthesis failed: {e}\")",
    "        print(\"   Note: FluidSynth may not be installed\")",
    "        return None, None",
    "",
    "print(\"\u2705 Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Select Audio File for PoC Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find audio files\n",
    "audio_extensions = ['*.mp3', '*.wav', '*.flac', '*.m4a', '*.ogg']\n",
    "audio_files = []\n",
    "for ext in audio_extensions:\n",
    "    audio_files.extend(glob.glob(os.path.join(original_dir, ext)))\n",
    "\n",
    "if len(audio_files) == 0:\n",
    "    print(\"\u274c No audio files found!\")\n",
    "    print(\"   Please upload audio files to the MT3 directory\")\n",
    "else:\n",
    "    print(f\"\u2705 Found {len(audio_files)} audio files:\")\n",
    "    for i, f in enumerate(audio_files):\n",
    "        info = torchaudio.info(f)\n",
    "        duration = info.num_frames / info.sample_rate\n",
    "        print(f\"   {i+1}. {os.path.basename(f)} ({duration:.1f}s)\")\n",
    "\n",
    "# File selector\n",
    "file_selector = widgets.Dropdown(\n",
    "    options=[(f\"{os.path.basename(f)} ({torchaudio.info(f).num_frames/torchaudio.info(f).sample_rate:.1f}s)\", f) for f in audio_files],\n",
    "    description='Test File:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='700px')\n",
    ")\n",
    "\n",
    "display(file_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run PoC Test: Full Mix vs Stems\n",
    "\n",
    "**Click the button below to start the test** (takes 3-5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global results storage\n",
    "poc_results = {}\n",
    "\n",
    "def run_poc_test(button):\n",
    "    global poc_results\n",
    "    \n",
    "    output.clear_output(wait=True)\n",
    "    \n",
    "    with output:\n",
    "        audio_path = file_selector.value\n",
    "        \n",
    "        if not audio_path:\n",
    "            print(\"\u274c Please select an audio file first!\")\n",
    "            return\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(\"\ud83c\udfaf PROOF OF CONCEPT TEST: Full Mix vs Stems\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"\\n\ud83d\udcc1 Test File: {os.path.basename(audio_path)}\")\n",
    "        \n",
    "        # Step 1: Transcribe full mix\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STEP 1: Transcribe Full Mix (Baseline)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        try:\n",
    "            fullmix_midi, fullmix_stats = transcribe_audio(audio_path, \"poc_fullmix\")\n",
    "            \n",
    "            print(f\"\\n\u2705 Full Mix Transcription Complete:\")\n",
    "            print(f\"   Total notes: {fullmix_stats['total_notes']}\")\n",
    "            print(f\"   Instruments: {fullmix_stats['num_instruments']}\")\n",
    "            print(f\"   Duration: {fullmix_stats['duration']:.2f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n\u274c Full mix transcription failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return\n",
    "        \n",
    "        # Step 2: Separate stems\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STEP 2: Separate Stems with Demucs\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        stems = separate_stems_demucs(audio_path, output_dir=\"separated\")\n",
    "        \n",
    "        if not stems:\n",
    "            print(\"\\n\u274c Stem separation failed! Stopping test.\")\n",
    "            print(\"   Make sure Demucs is loaded (run Cell 2)\")\n",
    "            return\n",
    "        \n",
    "        # Step 3: Transcribe each stem\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STEP 3: Transcribe Each Stem\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        stem_results = {}\n",
    "        \n",
    "        for stem_name, stem_path in stems.items():\n",
    "            print(f\"\\n\ud83c\udfb5 Transcribing {stem_name} stem...\")\n",
    "            \n",
    "            try:\n",
    "                stem_midi, stem_stats = transcribe_audio(stem_path, f\"poc_{stem_name}\")\n",
    "                stem_results[stem_name] = {\n",
    "                    'midi_path': stem_midi,\n",
    "                    'stats': stem_stats\n",
    "                }\n",
    "                \n",
    "                print(f\"   \u2705 {stem_name}: {stem_stats['total_notes']} notes, {stem_stats['num_instruments']} instruments\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   \u274c {stem_name} transcription failed: {e}\")\n",
    "                stem_results[stem_name] = {'error': str(e)}\n",
    "        \n",
    "        # Step 4: Compare results\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STEP 4: Comparison Analysis\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Store results\n",
    "        poc_results = {\n",
    "            'audio_path': audio_path,\n",
    "            'fullmix': {\n",
    "                'midi_path': fullmix_midi,\n",
    "                'stats': fullmix_stats\n",
    "            },\n",
    "            'stems': stems,\n",
    "            'stem_results': stem_results\n",
    "        }\n",
    "        \n",
    "        # Overall comparison\n",
    "        total_stem_notes = sum(r['stats']['total_notes'] for r in stem_results.values() if 'stats' in r)\n",
    "        \n",
    "        print(f\"\\n\ud83d\udcca Overall Note Count:\")\n",
    "        print(f\"   Full Mix: {fullmix_stats['total_notes']} notes\")\n",
    "        print(f\"   Stems Combined: {total_stem_notes} notes\")\n",
    "        improvement = ((total_stem_notes - fullmix_stats['total_notes']) / fullmix_stats['total_notes'] * 100) if fullmix_stats['total_notes'] > 0 else 0\n",
    "        print(f\"   Difference: {total_stem_notes - fullmix_stats['total_notes']:+d} notes ({improvement:+.1f}%)\")\n",
    "        \n",
    "        # Per-stem comparison\n",
    "        print(f\"\\n\ud83c\udfb8 Per-Stem Analysis:\")\n",
    "        for stem_name, result in stem_results.items():\n",
    "            if 'stats' in result:\n",
    "                print(f\"\\n   {stem_name.upper()}:\")\n",
    "                print(f\"      Notes detected: {result['stats']['total_notes']}\")\n",
    "                print(f\"      Instruments: {result['stats']['num_instruments']}\")\n",
    "                if result['stats']['instruments']:\n",
    "                    top_inst = sorted(result['stats']['instruments'], key=lambda x: x['notes'], reverse=True)[0]\n",
    "                    print(f\"      Top instrument: {top_inst['name']} ({top_inst['notes']} notes)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"\u2705 PoC TEST COMPLETE!\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"\\nRun the cells below to:\")\n",
    "        print(\"   - View detailed comparison tables\")\n",
    "        print(\"   - Listen to full mix vs stems\")\n",
    "        print(\"   - Get recommendation based on results\")\n",
    "\n",
    "# Create button and output\n",
    "poc_button = widgets.Button(\n",
    "    description='\ud83d\ude80 Run PoC Test',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='50px')\n",
    ")\n",
    "poc_button.on_click(run_poc_test)\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "print(\"\u26a0\ufe0f  Note: This test will take 3-5 minutes depending on audio length\")\n",
    "print(\"   - Full mix transcription: ~30s\")\n",
    "print(\"   - Stem separation: ~30-60s\")\n",
    "print(\"   - 4 stem transcriptions: ~2min\")\n",
    "print(\"\\n\u2705 Ready! Click the button above to start the test\")\n",
    "\n",
    "display(poc_button)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Detailed Results\n",
    "\n",
    "*Run this after the PoC test completes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if poc_results:\n",
    "    fullmix_notes = poc_results['fullmix']['stats']['total_notes']\n",
    "    total_stem_notes = sum(r['stats']['total_notes'] for r in poc_results['stem_results'].values() if 'stats' in r)\n",
    "    improvement = ((total_stem_notes - fullmix_notes) / fullmix_notes * 100) if fullmix_notes > 0 else 0\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"\ud83d\udcca PoC RESULTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n\ud83c\udfaf Improvement: {improvement:+.1f}%\")\n",
    "    print(f\"   Full Mix: {fullmix_notes} notes\")\n",
    "    print(f\"   Stems Combined: {total_stem_notes} notes\")\n",
    "    print(f\"   Difference: {total_stem_notes - fullmix_notes:+d} notes\\n\")\n",
    "    \n",
    "    if improvement > 10:\n",
    "        print(\"\u2705 RECOMMENDATION: PROCEED WITH IDEA 1 (Fine-tuning)\")\n",
    "        print(\"\\n   Stems approach validates the hypothesis!\")\n",
    "        print(\"   Fine-tuning will likely add another 10-15% improvement.\")\n",
    "        print(\"   Expected total improvement: 20-30%\\n\")\n",
    "        print(\"   Next steps:\")\n",
    "        print(\"   1. Read YOURMT3_FINETUNING_GUIDE.md\")\n",
    "        print(\"   2. Download Slakh2100 dataset (~1TB)\")\n",
    "        print(\"   3. Start fine-tuning bass model (3-5 days)\")\n",
    "        print(\"   4. Continue with other stems if bass succeeds\")\n",
    "    elif improvement > 5:\n",
    "        print(\"\u26a0\ufe0f  RECOMMENDATION: INVESTIGATE FURTHER\")\n",
    "        print(\"\\n   Moderate improvement detected.\")\n",
    "        print(\"   Check stem quality and per-stem results.\\n\")\n",
    "        print(\"   Action items:\")\n",
    "        print(\"   1. Listen to separated stems (next cell)\")\n",
    "        print(\"   2. Check which stems work best\")\n",
    "        print(\"   3. Try different Demucs model: mdx_extra\")\n",
    "        print(\"   4. Re-run PoC with better separation\")\n",
    "    else:\n",
    "        print(\"\u274c RECOMMENDATION: RECONSIDER APPROACH\")\n",
    "        print(\"\\n   Stems not providing expected benefit.\")\n",
    "        print(\"   Fine-tuning may not help.\\n\")\n",
    "        print(\"   Alternatives:\")\n",
    "        print(\"   1. Investigate Demucs quality (listen to stems)\")\n",
    "        print(\"   2. Try Idea 2 (instrument matching)\")\n",
    "        print(\"   3. Use different stem separation (Spleeter, Open-Unmix)\")\n",
    "        print(\"   4. Hybrid approach: stems for specific instruments only\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Run the PoC test first (Cell 6)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Piano Roll Visualization\n",
    "\n",
    "*Visual comparison of MIDI transcriptions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if poc_results:",
    "    print(\"\ud83c\udfb9 Piano Roll Visualizations with MIDI Playback\")",
    "    print(\"=\"*80)",
    "    ",
    "    def plot_piano_roll(midi_path, title, ax=None):",
    "        \"\"\"Plot piano roll from MIDI file\"\"\"",
    "        midi = pretty_midi.PrettyMIDI(midi_path)",
    "        ",
    "        if ax is None:",
    "            fig, ax = plt.subplots(figsize=(16, 6))",
    "        ",
    "        # Get all notes",
    "        notes_to_plot = []",
    "        colors = plt.cm.tab20.colors",
    "        ",
    "        for inst_idx, inst in enumerate(midi.instruments):",
    "            color = colors[inst_idx % len(colors)]",
    "            for note in inst.notes:",
    "                notes_to_plot.append({",
    "                    'start': note.start,",
    "                    'end': note.end,",
    "                    'pitch': note.pitch,",
    "                    'velocity': note.velocity,",
    "                    'color': color,",
    "                    'instrument': inst.program,",
    "                    'is_drum': inst.is_drum",
    "                })",
    "        ",
    "        # Plot notes",
    "        for note_info in notes_to_plot:",
    "            ax.add_patch(",
    "                plt.Rectangle(",
    "                    (note_info['start'], note_info['pitch']),",
    "                    note_info['end'] - note_info['start'],",
    "                    1,",
    "                    facecolor=note_info['color'],",
    "                    edgecolor='black',",
    "                    linewidth=0.5,",
    "                    alpha=0.7",
    "                )",
    "            )",
    "        ",
    "        ax.set_xlim(0, midi.get_end_time())",
    "        ax.set_ylim(20, 108)  # Piano range",
    "        ax.set_xlabel('Time (seconds)', fontsize=12)",
    "        ax.set_ylabel('MIDI Pitch', fontsize=12)",
    "        ax.set_title(title, fontsize=14, fontweight='bold')",
    "        ax.grid(True, alpha=0.3)",
    "        ",
    "        # Add note count",
    "        total_notes = len(notes_to_plot)",
    "        ax.text(0.98, 0.02, f'{total_notes} notes', ",
    "                transform=ax.transAxes,",
    "                ha='right', va='bottom',",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),",
    "                fontsize=10)",
    "        ",
    "        return ax",
    "    ",
    "    print(\"\\n\ud83d\udcca Generating visualizations...\")",
    "    ",
    "    # 1. Full Mix",
    "    print(\"\\n\" + \"=\"*80)",
    "    print(\"\ud83c\udfb5 FULL MIX (Baseline)\")",
    "    print(\"=\"*80)",
    "    ",
    "    fig, ax = plt.subplots(figsize=(18, 4))",
    "    plot_piano_roll(poc_results['fullmix']['midi_path'], ",
    "                    '\ud83c\udfb5 Full Mix Transcription', ax)",
    "    plt.tight_layout()",
    "    plt.show()",
    "    ",
    "    print(\"\\n\ud83d\udd0a Audio Playback:\")",
    "    audio, sr = midi_to_audio(poc_results['fullmix']['midi_path'])",
    "    if audio is not None:",
    "        display(Audio(audio, rate=sr))",
    "    ",
    "    # 2. Each Stem",
    "    stem_names = ['drums', 'bass', 'other', 'vocals']",
    "    stem_emojis = {'drums': '\ud83e\udd41', 'bass': '\ud83c\udfb8', 'other': '\ud83c\udfb9', 'vocals': '\ud83c\udfa4'}",
    "    ",
    "    for stem_name in stem_names:",
    "        if stem_name in poc_results['stem_results'] and 'midi_path' in poc_results['stem_results'][stem_name]:",
    "            print(\"\\n\" + \"=\"*80)",
    "            print(f\"{stem_emojis[stem_name]} {stem_name.upper()} STEM\")",
    "            print(\"=\"*80)",
    "            ",
    "            fig, ax = plt.subplots(figsize=(18, 4))",
    "            plot_piano_roll(poc_results['stem_results'][stem_name]['midi_path'],",
    "                            f'{stem_emojis[stem_name]} {stem_name.title()} Stem Transcription',",
    "                            ax)",
    "            plt.tight_layout()",
    "            plt.show()",
    "            ",
    "            print(\"\\n\ud83d\udd0a Audio Playback:\")",
    "            audio, sr = midi_to_audio(poc_results['stem_results'][stem_name]['midi_path'])",
    "            if audio is not None:",
    "                display(Audio(audio, rate=sr))",
    "    ",
    "    print(\"\\n\" + \"=\"*80)",
    "    print(\"\u2705 All visualizations generated!\")",
    "    print(\"=\"*80)",
    "    print(\"\\n\ud83d\udca1 Visual Insights:\")",
    "    print(\"   - Vertical position = pitch (higher = higher note)\")",
    "    print(\"   - Horizontal position = time\")",
    "    print(\"   - Rectangle width = note duration\")",
    "    print(\"   - Colors = different instruments\")",
    "    print(\"   - Compare density to see which stem has more detected notes\")",
    "    print(\"   - Listen to MIDI playback to verify transcription quality\")",
    "    ",
    "else:",
    "    print(\"\u26a0\ufe0f  Run the PoC test first (Cell 6)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Listen to Stems Quality\n",
    "\n",
    "*Verify stem separation quality*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if poc_results:\n",
    "    print(\"\ud83c\udfa7 Audio Playback: Original vs Stems\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Original audio\n",
    "    print(\"\\n\ud83c\udfb5 Original Full Mix:\")\n",
    "    waveform, sr = torchaudio.load(poc_results['audio_path'])\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "    display(Audio(waveform.numpy(), rate=sr))\n",
    "    \n",
    "    # Each stem\n",
    "    for stem_name, stem_path in poc_results['stems'].items():\n",
    "        print(f\"\\n\ud83c\udfb8 {stem_name.title()} Stem:\")\n",
    "        waveform, sr = torchaudio.load(stem_path)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        display(Audio(waveform.numpy(), rate=sr))\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Run the PoC test first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results\n",
    "\n",
    "*Export PoC results to JSON*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if poc_results:\n",
    "    # Save results as JSON\n",
    "    results_summary = {\n",
    "        'test_file': os.path.basename(poc_results['audio_path']),\n",
    "        'fullmix': {\n",
    "            'notes': poc_results['fullmix']['stats']['total_notes'],\n",
    "            'instruments': poc_results['fullmix']['stats']['num_instruments'],\n",
    "            'duration': poc_results['fullmix']['stats']['duration']\n",
    "        },\n",
    "        'stems': {}\n",
    "    }\n",
    "    \n",
    "    for stem_name, result in poc_results['stem_results'].items():\n",
    "        if 'stats' in result:\n",
    "            results_summary['stems'][stem_name] = {\n",
    "                'notes': result['stats']['total_notes'],\n",
    "                'instruments': result['stats']['num_instruments']\n",
    "            }\n",
    "    \n",
    "    # Calculate overall improvement\n",
    "    fullmix_notes = results_summary['fullmix']['notes']\n",
    "    total_stem_notes = sum(s['notes'] for s in results_summary['stems'].values())\n",
    "    improvement = ((total_stem_notes - fullmix_notes) / fullmix_notes * 100) if fullmix_notes > 0 else 0\n",
    "    \n",
    "    results_summary['improvement'] = {\n",
    "        'absolute': total_stem_notes - fullmix_notes,\n",
    "        'percentage': improvement\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    output_path = os.path.join(original_dir, 'poc_results.json')\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(results_summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\u2705 PoC results saved to: {output_path}\")\n",
    "    print(f\"\\n\ud83d\udcc4 Summary:\")\n",
    "    print(json.dumps(results_summary, indent=2))\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Run the PoC test first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83c\udf89 PoC Complete!\n",
    "\n",
    "**If improvement >10%**: Proceed with fine-tuning (see `YOURMT3_FINETUNING_GUIDE.md`)\n",
    "\n",
    "**If improvement 5-10%**: Investigate stem quality, try different Demucs model\n",
    "\n",
    "**If improvement <5%**: Consider Idea 2 (instrument matching) or improve stem separation\n",
    "\n",
    "---\n",
    "\n",
    "*Assisted by Claude Code*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}