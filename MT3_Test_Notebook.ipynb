{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT3 PyTorch - Test Notebook\n",
    "\n",
    "Complete testing notebook for MT3 audio-to-MIDI transcription on Brev Nvidia instances.\n",
    "\n",
    "## Features\n",
    "- ‚úÖ Dependency verification\n",
    "- ‚úÖ Model loading and validation\n",
    "- ‚úÖ Audio transcription examples\n",
    "- ‚úÖ Multiple generation strategies\n",
    "- ‚úÖ Result visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's verify all dependencies are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "!pip install -q torch librosa soundfile note-seq pretty-midi absl-py tqdm numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"Running on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import MT3 Modules\n",
    "\n",
    "Test that all MT3 modules can be imported correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MT3 modules\n",
    "try:\n",
    "    from models import MT3Model, MT3Config\n",
    "    from models.checkpoint_utils import load_mt3_checkpoint\n",
    "    print(\"‚úÖ Models module imported\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to import models: {e}\")\n",
    "\n",
    "try:\n",
    "    from preprocessing import AudioPreprocessor, AudioPreprocessingConfig\n",
    "    print(\"‚úÖ Preprocessing module imported\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to import preprocessing: {e}\")\n",
    "\n",
    "try:\n",
    "    from decoder.decoder import MT3TokenDecoder\n",
    "    print(\"‚úÖ Decoder module imported\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to import decoder: {e}\")\n",
    "\n",
    "try:\n",
    "    from inference import MT3Inference\n",
    "    print(\"‚úÖ Inference module imported\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to import inference: {e}\")\n",
    "\n",
    "print(\"\\nüéâ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Set up paths and device configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Configuration\n",
    "CHECKPOINT_PATH = \"mt3_converted.pth\"  # Update this path if needed\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "OUTPUT_DIR = \"output_midi\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Checkpoint path: {CHECKPOINT_PATH}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Check if checkpoint exists\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"‚úÖ Checkpoint found ({os.path.getsize(CHECKPOINT_PATH) / 1e6:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Checkpoint not found at {CHECKPOINT_PATH}\")\n",
    "    print(\"   Please download or specify correct path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize MT3 Inference\n",
    "\n",
    "Load the model and prepare for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize inference handler\n",
    "print(\"Loading MT3 model...\")\n",
    "\n",
    "inference = MT3Inference(\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    device=DEVICE,\n",
    "    num_velocity_bins=1  # Use 1 for simple velocity, 127 for full range\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# Display model information\n",
    "info = inference.get_model_info()\n",
    "print(f\"\\nModel Information:\")\n",
    "print(f\"  Parameters: {info['model']['parameters']['total']:,}\")\n",
    "print(f\"  Vocab size: {info['decoder']['num_classes']}\")\n",
    "print(f\"  Sample rate: {info['preprocessor']['sample_rate']} Hz\")\n",
    "print(f\"  Mel bins: {info['preprocessor']['n_mels']}\")\n",
    "print(f\"  Device: {info['device']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test with Audio File\n",
    "\n",
    "Upload an audio file and transcribe it to MIDI.\n",
    "\n",
    "### Option A: Upload audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Jupyter environments with file upload widget\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.wav,.mp3,.flac,.m4a',\n",
    "    multiple=False,\n",
    "    description='Upload Audio'\n",
    ")\n",
    "\n",
    "display(uploader)\n",
    "print(\"Upload an audio file (.wav, .mp3, .flac, .m4a)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Specify audio file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or specify path directly\n",
    "AUDIO_FILE = \"path/to/your/audio.wav\"  # Update this path\n",
    "\n",
    "# Check if file exists\n",
    "if os.path.exists(AUDIO_FILE):\n",
    "    print(f\"‚úÖ Audio file found: {AUDIO_FILE}\")\n",
    "    print(f\"   Size: {os.path.getsize(AUDIO_FILE) / 1e6:.2f} MB\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Audio file not found: {AUDIO_FILE}\")\n",
    "    print(\"   Please update AUDIO_FILE path or use upload widget above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transcribe Audio ‚Üí MIDI\n",
    "\n",
    "### Basic Transcription (Greedy Decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Basic transcription with greedy decoding\n",
    "output_path = os.path.join(OUTPUT_DIR, \"transcription_greedy.mid\")\n",
    "\n",
    "print(\"üéµ Transcribing audio (greedy decoding)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "result = inference.transcribe(\n",
    "    audio_path=AUDIO_FILE,\n",
    "    output_path=output_path,\n",
    "    max_length=1024,\n",
    "    do_sample=False  # Greedy decoding\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Transcription complete!\")\n",
    "print(f\"   Output: {result['midi_path']}\")\n",
    "print(f\"   Notes: {result['num_notes']}\")\n",
    "print(f\"   Duration: {result['duration']:.2f}s\")\n",
    "print(f\"   Processing time: {elapsed:.2f}s\")\n",
    "print(f\"   Speed: {result['duration']/elapsed:.2f}x realtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcription with Sampling (More Creative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcription with temperature sampling\n",
    "output_path = os.path.join(OUTPUT_DIR, \"transcription_sampling.mid\")\n",
    "\n",
    "print(\"üéµ Transcribing audio (temperature sampling)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "result = inference.transcribe(\n",
    "    audio_path=AUDIO_FILE,\n",
    "    output_path=output_path,\n",
    "    max_length=1024,\n",
    "    do_sample=True,\n",
    "    temperature=0.8,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Transcription complete!\")\n",
    "print(f\"   Output: {result['midi_path']}\")\n",
    "print(f\"   Notes: {result['num_notes']}\")\n",
    "print(f\"   Processing time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Audio Transcription (with Chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For audio files longer than 30 seconds\n",
    "output_path = os.path.join(OUTPUT_DIR, \"transcription_long.mid\")\n",
    "\n",
    "print(\"üéµ Transcribing long audio (with chunking)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "result = inference.transcribe_long_audio(\n",
    "    audio_path=AUDIO_FILE,\n",
    "    output_path=output_path,\n",
    "    chunk_length=256,  # ~30 seconds per chunk\n",
    "    max_length=1024\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Transcription complete!\")\n",
    "print(f\"   Output: {result['midi_path']}\")\n",
    "print(f\"   Notes: {result['num_notes']}\")\n",
    "print(f\"   Chunks: {result['num_chunks']}\")\n",
    "print(f\"   Processing time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Results\n",
    "\n",
    "Inspect the generated MIDI file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import note_seq\n",
    "import pretty_midi\n",
    "\n",
    "# Load MIDI file\n",
    "midi_path = result['midi_path']\n",
    "ns = result['note_sequence']\n",
    "\n",
    "print(f\"üìä MIDI Analysis: {os.path.basename(midi_path)}\")\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(f\"  Total notes: {len(ns.notes)}\")\n",
    "print(f\"  Duration: {ns.total_time:.2f}s\")\n",
    "\n",
    "# Analyze instruments\n",
    "programs = {}\n",
    "drums = []\n",
    "for note in ns.notes:\n",
    "    if note.is_drum:\n",
    "        drums.append(note.pitch)\n",
    "    else:\n",
    "        programs[note.program] = programs.get(note.program, 0) + 1\n",
    "\n",
    "print(f\"\\nInstruments detected:\")\n",
    "if programs:\n",
    "    for program, count in sorted(programs.items()):\n",
    "        print(f\"  Program {program}: {count} notes\")\n",
    "if drums:\n",
    "    print(f\"  Drums: {len(drums)} hits\")\n",
    "\n",
    "# Pitch distribution\n",
    "pitches = [note.pitch for note in ns.notes if not note.is_drum]\n",
    "if pitches:\n",
    "    print(f\"\\nPitch range:\")\n",
    "    print(f\"  Lowest: {min(pitches)} ({pretty_midi.note_number_to_name(min(pitches))})\")\n",
    "    print(f\"  Highest: {max(pitches)} ({pretty_midi.note_number_to_name(max(pitches))})\")\n",
    "\n",
    "# Note duration statistics\n",
    "durations = [note.end_time - note.start_time for note in ns.notes]\n",
    "if durations:\n",
    "    import numpy as np\n",
    "    print(f\"\\nNote durations:\")\n",
    "    print(f\"  Mean: {np.mean(durations):.3f}s\")\n",
    "    print(f\"  Min: {min(durations):.3f}s\")\n",
    "    print(f\"  Max: {max(durations):.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Processing\n",
    "\n",
    "Process multiple audio files at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Process multiple files\n",
    "audio_files = [\n",
    "    \"path/to/audio1.wav\",\n",
    "    \"path/to/audio2.wav\",\n",
    "    \"path/to/audio3.wav\"\n",
    "]\n",
    "\n",
    "# Filter existing files\n",
    "audio_files = [f for f in audio_files if os.path.exists(f)]\n",
    "\n",
    "if audio_files:\n",
    "    print(f\"Processing {len(audio_files)} files...\\n\")\n",
    "    \n",
    "    results = inference.transcribe_batch(\n",
    "        audio_files=audio_files,\n",
    "        output_dir=OUTPUT_DIR\n",
    "    )\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nüìä Batch Processing Summary:\")\n",
    "    successful = [r for r in results if 'num_notes' in r]\n",
    "    failed = [r for r in results if 'error' in r]\n",
    "    \n",
    "    print(f\"  Successful: {len(successful)}/{len(audio_files)}\")\n",
    "    print(f\"  Failed: {len(failed)}/{len(audio_files)}\")\n",
    "    \n",
    "    if successful:\n",
    "        total_notes = sum(r['num_notes'] for r in successful)\n",
    "        print(f\"  Total notes: {total_notes}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No audio files found. Update the audio_files list.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compare Generation Strategies\n",
    "\n",
    "Test different decoding strategies on the same audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [\n",
    "    {\"name\": \"Greedy\", \"do_sample\": False},\n",
    "    {\"name\": \"Temperature 0.5\", \"do_sample\": True, \"temperature\": 0.5},\n",
    "    {\"name\": \"Temperature 0.8\", \"do_sample\": True, \"temperature\": 0.8},\n",
    "    {\"name\": \"Top-k 50\", \"do_sample\": True, \"top_k\": 50},\n",
    "    {\"name\": \"Top-p 0.9\", \"do_sample\": True, \"top_p\": 0.9},\n",
    "]\n",
    "\n",
    "print(\"üéØ Testing different generation strategies...\\n\")\n",
    "\n",
    "comparison = []\n",
    "for strategy in strategies:\n",
    "    name = strategy.pop(\"name\")\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"strategy_{name.replace(' ', '_').lower()}.mid\")\n",
    "    \n",
    "    print(f\"Testing: {name}...\")\n",
    "    start = time.time()\n",
    "    \n",
    "    result = inference.transcribe(\n",
    "        audio_path=AUDIO_FILE,\n",
    "        output_path=output_path,\n",
    "        max_length=512,  # Shorter for comparison\n",
    "        **strategy\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    comparison.append({\n",
    "        \"strategy\": name,\n",
    "        \"notes\": result['num_notes'],\n",
    "        \"time\": elapsed\n",
    "    })\n",
    "    \n",
    "print(f\"\\nüìä Strategy Comparison:\")\n",
    "print(f\"{'Strategy':<20} {'Notes':<10} {'Time (s)':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for c in comparison:\n",
    "    print(f\"{c['strategy']:<20} {c['notes']:<10} {c['time']:<10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Download Results\n",
    "\n",
    "List all generated MIDI files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all MIDI files in output directory\n",
    "import glob\n",
    "\n",
    "midi_files = glob.glob(os.path.join(OUTPUT_DIR, \"*.mid\"))\n",
    "\n",
    "print(f\"üìÅ Generated MIDI files ({len(midi_files)}):\")\n",
    "for midi_file in midi_files:\n",
    "    size = os.path.getsize(midi_file) / 1024\n",
    "    print(f\"  ‚Ä¢ {os.path.basename(midi_file)} ({size:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nüíæ Files saved in: {OUTPUT_DIR}/\")\n",
    "print(\"   You can download them from the file browser or use:\")\n",
    "print(f\"   !zip -r output_midi.zip {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Performance Benchmarking\n",
    "\n",
    "Test model performance on different audio lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark inference speed\n",
    "import librosa\n",
    "\n",
    "if os.path.exists(AUDIO_FILE):\n",
    "    # Load audio to get duration\n",
    "    audio, sr = librosa.load(AUDIO_FILE, sr=16000)\n",
    "    audio_duration = len(audio) / sr\n",
    "    \n",
    "    print(f\"üìä Performance Benchmark\")\n",
    "    print(f\"Audio duration: {audio_duration:.2f}s\\n\")\n",
    "    \n",
    "    # Run multiple times for average\n",
    "    times = []\n",
    "    for i in range(3):\n",
    "        start = time.time()\n",
    "        result = inference.transcribe(\n",
    "            audio_path=AUDIO_FILE,\n",
    "            output_path=os.path.join(OUTPUT_DIR, f\"bench_{i}.mid\"),\n",
    "            max_length=512,\n",
    "            do_sample=False\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "        times.append(elapsed)\n",
    "        print(f\"  Run {i+1}: {elapsed:.2f}s ({audio_duration/elapsed:.2f}x realtime)\")\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    print(f\"\\nAverage: {avg_time:.2f}s ({audio_duration/avg_time:.2f}x realtime)\")\n",
    "    print(f\"Throughput: {audio_duration/avg_time:.2f}x faster than realtime\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Audio file not found for benchmarking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Cleanup\n",
    "\n",
    "Optional: Clean up test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to clean up test files\n",
    "# import shutil\n",
    "# shutil.rmtree(OUTPUT_DIR)\n",
    "# print(f\"‚úÖ Cleaned up {OUTPUT_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook tested:\n",
    "- ‚úÖ MT3 model loading and initialization\n",
    "- ‚úÖ Audio transcription with multiple strategies\n",
    "- ‚úÖ Long audio processing with chunking\n",
    "- ‚úÖ Batch processing capabilities\n",
    "- ‚úÖ Performance benchmarking\n",
    "\n",
    "### Next Steps\n",
    "1. Try with your own audio files\n",
    "2. Experiment with different generation parameters\n",
    "3. Compare results with different velocity bins (1 vs 127)\n",
    "4. Fine-tune for your specific use case\n",
    "\n",
    "### Resources\n",
    "- GitHub: https://github.com/Pyzeur-ColonyLab/MT3_2025\n",
    "- Documentation: See README.md and module-specific READMEs\n",
    "- MT3 Paper: https://arxiv.org/abs/2111.03017"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}