# YourMT3 Setup et Utilisation

## âœ… Ã‰tapes ComplÃ©tÃ©es

1. âœ… Clone du Space YourMT3
2. âœ… Authentification HuggingFace
3. âœ… TÃ©lÃ©chargement du checkpoint (536 MB)
4. âœ… Script de test crÃ©Ã©

## ğŸ“¦ Installation des DÃ©pendances

### Option 1: Environnement Virtuel (RecommandÃ©)

```bash
cd /Volumes/T7/Dyapason/instrument-recognition-app/MT3

# CrÃ©er environnement virtuel
python3 -m venv venv_yourmt3

# Activer
source venv_yourmt3/bin/activate

# Installer dÃ©pendances YourMT3
pip install torch torchaudio
pip install pytorch-lightning>=2.2.1
pip install transformers==4.45.1
pip install librosa einops mido
pip install pretty_midi  # Pour analyser les rÃ©sultats

# Installer dÃ©pendances YourMT3 complÃ¨tes
pip install -r yourmt3_space/requirements.txt
```

### Option 2: Installation Globale

```bash
pip3 install torch torchaudio pytorch-lightning transformers==4.45.1 librosa einops mido pretty_midi
```

## ğŸš€ ExÃ©cution du Test

```bash
cd /Volumes/T7/Dyapason/instrument-recognition-app/MT3

# Avec environnement virtuel
source venv_yourmt3/bin/activate
python test_yourmt3.py

# Ou directement
python3 test_yourmt3.py
```

## ğŸ“ Structure des Fichiers

```
MT3/
â”œâ”€â”€ test_yourmt3.py                  # Script de test (CRÃ‰Ã‰)
â”œâ”€â”€ 02.HowardShore-TheShire.flac     # Audio source (149s)
â”œâ”€â”€ yourmt3_space/                   # Clone du Space HF
â”‚   â”œâ”€â”€ amt/src/                     # Code source YourMT3
â”‚   â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”‚   â”œâ”€â”€ ymt3.py              # ModÃ¨le principal
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”œâ”€â”€ amt/logs/2024/
â”‚   â”‚   â””â”€â”€ mc13_256_g4.../checkpoints/
â”‚   â”‚       â””â”€â”€ last.ckpt            # Checkpoint (536 MB) âœ…
â”‚   â”œâ”€â”€ model_helper.py              # Helpers chargement/infÃ©rence
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ model_output/                    # MIDI output (sera crÃ©Ã©)
    â””â”€â”€ TheShire_YourMT3.mid
```

## ğŸ¯ RÃ©sultat Attendu

**Si succÃ¨s**:
```
============================================================
YourMT3 Test: The Shire Transcription
============================================================

1. Loading YourMT3 model...
   Device: cuda (ou cpu)
   Model: YPTF.MoE+Multi (noPS)
   âœ… Model loaded successfully

2. Loading audio: 02.HowardShore-TheShire.flac
   Duration: 149.48s
   Sample rate: 44100 Hz
   Channels: 2

3. Transcribing with YourMT3...
   Converting audio... X.XXs
   Model inference... X.XXs
   Post processing... X.XXs

âœ… Transcription complete!
   MIDI file: ./model_output/TheShire_YourMT3.mid
   File size: XXXXX bytes
   Total notes: XXX (devrait Ãªtre > 0!)
   Instruments: X

   âœ… SUCCESS: XXX notes detected!

============================================================
YourMT3 test complete
============================================================
```

**Comparaison avec MT3 converti**:
- MT3: **0 notes** (vocabulaire mismatch)
- YourMT3: **> 0 notes** attendu (qualitÃ© 5/10 selon dÃ©mo)

## ğŸ” DÃ©pannage

### Erreur: `ModuleNotFoundError: No module named 'torch'`
â†’ Installer les dÃ©pendances (voir ci-dessus)

### Erreur: `No such file or directory: yourmt3_space/amt/src`
â†’ VÃ©rifier que vous Ãªtes dans le bon rÃ©pertoire: `cd /Volumes/T7/Dyapason/instrument-recognition-app/MT3`

### Erreur: Checkpoint not found
â†’ VÃ©rifier le checkpoint:
```bash
ls -lh yourmt3_space/amt/logs/2024/mc13_256_g4_all_v7_mt3f_sqr_rms_moe_wf4_n8k2_silu_rope_rp_b36_nops/checkpoints/last.ckpt
# Devrait montrer 536M
```

### MÃ©moire insuffisante
â†’ RÃ©duire batch size dans model_helper.py ligne 141:
```python
pred_token_arr, _ = model.inference_file(bsz=4, ...)  # au lieu de bsz=8
```

## ğŸ“Š Prochaines Ã‰tapes

1. **ExÃ©cuter le test** â†’ Voir si YourMT3 gÃ©nÃ¨re des notes
2. **Analyser le MIDI** â†’ Comparer avec dÃ©mo HF
3. **DÃ©cider**:
   - Si qualitÃ© acceptable (â‰¥4/10) â†’ IntÃ©grer YourMT3
   - Si qualitÃ© insuffisante â†’ Tester Basic-Pitch
4. **Nettoyer** â†’ Supprimer fichiers temporaires MT3

## ğŸµ Notes Techniques

**Configuration ModÃ¨le**:
- Encoder: Perceiver-TF + MoE (8 experts, top-2)
- Decoder: Multi-channel T5 (13 instruments)
- Audio: Spectrogram (512 bins), hop=300
- Tokenizer: MT3 + Singing extension
- Inference: BF16/FP16 precision

**Temps d'exÃ©cution estimÃ©**:
- CPU: ~10-15 minutes pour 149s audio
- GPU (CUDA): ~2-3 minutes
